Q&A chatbot application using local Ollama.

1. Open source model gemma2

2. Streamlit for front end page creation

3. Langchain smith for tracing

Please refer to the attached images to see working application.

Steps to run application in your local:
1. Download Ollama from https://ollama.com/download
2. From command prompt run the below command to download model of your choice:

    ollam run gemma2
3. Download the project files and run the application using
   streamlit run app.py
   
   
